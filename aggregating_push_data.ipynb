{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e04c21bb-f046-44e3-8680-7e9efe43dbec",
   "metadata": {},
   "source": [
    "## Step 1: Exogenous Shock\n",
    "1. Create measure of code quality\n",
    "   \n",
    "    a. Measure of user-side code quality\n",
    "   \n",
    "    b. Measure of maintainer-side code quality\n",
    "3. Analyze contributions made\n",
    "4. Hypothesize how my instrument/exogenous affects either, and examine the empirical effect\n",
    "\n",
    "## Step 2: \n",
    "How do I actually perform analysis?\n",
    "1. Measure 1: Compare within repository groups\n",
    "2. Measure 2: Find some other way to weight what a \"download\" means? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3521104c-0ae8-49ae-9d11-b59d15a4d079",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import ast\n",
    "#from pandarallel import pandarallel\n",
    "import glob\n",
    "import json\n",
    "import sys\n",
    "import numpy as np\n",
    "from itertools import chain\n",
    "import dask.dataframe as da\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc0b5ef0-c2e2-4c99-a786-f9920352d3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pandarallel.initialize(progress_bar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7d13816-b0c2-49da-a58a-8e083aeea2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_actor_info = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84fad82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"github_data_pre_18\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0b7c4d8-3b5f-432f-a5d4-1cac4c175a6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading push data\n"
     ]
    }
   ],
   "source": [
    "#folder = sys.argv[1]\n",
    "print(\"reading push data\")\n",
    "df_push = pd.DataFrame()\n",
    "file_count = np.array([int(ele.replace(\"pushEvent000000000\",\"\").replace(\".csv\",\"\")) for ele in os.listdir(f'data/github_clean/{folder}/') if 'pushEvent000000000' in ele])\n",
    "\n",
    "for i in range(max(file_count)+1):\n",
    "    if int(i) < 10:\n",
    "        i = f\"0{i}\"\n",
    "    if int(i) < 100:\n",
    "        i = f\"0{i}\"\n",
    "    df_push_i = pd.read_csv(f'data/github_clean/{folder}/pushEvent000000000{i}.csv', index_col = 0)\n",
    "    df_push = pd.concat([df_push_i, df_push])\n",
    "    \n",
    "df_actor_info = df_push.groupby(['actor_id', 'actor_login', 'repo_name', 'repo_id', 'org_id','org_login']).agg(\n",
    "    {'created_at': ['min', 'max']})\n",
    "df_actor_info.columns = ['earliest_date', 'latest_date']\n",
    "df_actor_info = df_actor_info.reset_index()\n",
    "df_push = df_push[['type', 'created_at', 'repo_id', 'actor_id', 'org_id', 'push_id',\n",
    "                   'push_size', 'push_size_distinct', 'push_before', 'push_head']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d0e8cd4-b8a7-4d1c-9af1-c75c7190e827",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanParquetPushes(f):\n",
    "    try:\n",
    "        df_parquet_repo = pd.read_parquet(f)\n",
    "        df_parquet_repo['ordering'] = df_parquet_repo.groupby('push_id').cumcount()+1\n",
    "        df_parquet_repo = df_parquet_repo[['push_id', 'repo_id', 'actor_id','push_size', 'commit_groups',\n",
    "                                           'commit sha', 'ordering', 'commit author name', 'commit author email',\n",
    "                                               'committer name','commmitter email','commit message', 'commit additions',\n",
    "                                           'commit deletions','commit changes total','commit files changed count',\n",
    "                                           'commit file changes', 'commit time']]\n",
    "    except:\n",
    "        df_parquet_repo = pd.DataFrame()\n",
    "        print(f)\n",
    "    return df_parquet_repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd37e1f7-0866-42dc-a8f7-b9afacf9f394",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "files = glob.glob(f\"data/github_commits/parquet/{folder}/*_push_*\")\n",
    "df_parquet_pushes_data = [cleanParquetPushes(f) for f in files]\n",
    "df_parquet_pushes = pd.concat(df_parquet_pushes_data,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "008592c4-3ea6-4aa9-a8cf-8878c8d00d38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_parquet_pushes['commit_groups'] = df_parquet_pushes['commit_groups'].apply(lambda x: ast.literal_eval if type(x) == str else x)\n",
    "df_parquet_pushes['commit parent'] = df_parquet_pushes['commit_groups'].apply(lambda x: x[0] if len(x)>0 else '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72e798db-a257-4b5b-8da9-a2edbf39697b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parquet_pushes.drop('commit_groups', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "946cc954-101c-4bc8-ab36-bafa37d03c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_push['created_at'] = pd.to_datetime(df_push['created_at'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84fa2ff2-2a10-4cff-a5f7-26934ee16d67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_push_commits = pd.merge(df_push, df_parquet_pushes, how = 'left',\n",
    "                           on = ['repo_id', 'push_id', 'actor_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06a68d56-0ba2-4030-a540-cb7a5c431850",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_push_commits['commit time'] = pd.to_datetime(df_push_commits['commit time'],unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef8c8806-5c63-4358-ab7f-0aed0a8e5e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_push_commits['push_day'] = df_push_commits['created_at'].apply(lambda x: x.day)\n",
    "df_push_commits['push_month'] = df_push_commits['created_at'].apply(lambda x: x.month)\n",
    "df_push_commits['push_year'] = df_push_commits['created_at'].apply(lambda x: x.year)\n",
    "\n",
    "df_push_commits['commit_day'] = df_push_commits['commit time'].apply(lambda x: x.day)\n",
    "df_push_commits['commit_month'] = df_push_commits['commit time'].apply(lambda x: x.month)\n",
    "df_push_commits['commit_year'] = df_push_commits['commit time'].apply(lambda x: x.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16e6c65b-9967-4f28-82f4-855e541024ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_push_commits = df_push_commits.rename({'push_size_x':'push_size'}, axis = 1).drop('push_size_y', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a774cae0-dd2f-4a30-9782-d810ea3ddfa1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_push_commits['commit file changes'] = df_push_commits['commit file changes'].apply(\n",
    "    lambda x: [] if type(x) == float or type(x) == type(None) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15801f9d-4601-4476-a07d-465aa2d8f714",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_push_commits_s = df_push_commits#.sample(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67485c0e-15eb-4744-94bd-2284a876e11b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "null_commit_time = df_push_commits_s[df_push_commits_s['commit_year'].isnull()].index\n",
    "df_push_commits_s.loc[null_commit_time, \n",
    "    ['commit_day', 'commit_month', 'commit_year']] = df_push_commits_s.loc[null_commit_time, ['push_day', 'push_month', 'push_year']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e98ca01-424b-49cf-bf93-3818a3d5e369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 1 µs, total: 5 µs\n",
      "Wall time: 8.34 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#df_push_commits_s = pd.read_csv('data/merged_data/merged_commit_push.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d924190b-b4f3-43bf-89c6-23d106ec6af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_push_commits_s['committer info'] = df_push_commits_s['committer name'] + \" | \" + df_push_commits_s['commmitter email']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d45895d9-b749-4f8a-acd7-ab551850116f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getList(x):\n",
    "    try:\n",
    "        return [ele['file'] for ele in x]\n",
    "    except:\n",
    "        return [ele['file'] for sublst in x for ele in sublst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a8059612",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_push_commits_s['commit file changes'] = df_push_commits_s['commit file changes'].apply(lambda x: x.decode() if type(x) == bytes else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bf9ecb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_push\n",
    "del df_parquet_pushes\n",
    "del df_push_commits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be44844-aabb-4c46-8316-ddba9eb52b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_push_commits_s['commit file changes'] = df_push_commits_s['commit file changes'].apply(lambda x: ast.literal_eval(x) if type(x) == str else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e3d84a-f900-4ee0-be96-a6551cc36c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check to make sure each push is associated with one actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61069e2f-334a-4e94-ad19-0c757b89499f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropNAUnique(x):\n",
    "    return x.dropna().unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8241b8c0-8cc4-4eee-bb09-76b754c8bd78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_push_commits_s['push_size_wt'] = df_push_commits_s['push_size'] / df_push_commits_s.groupby('push_id')['push_id'].transform('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702f9dea-8f80-41dd-8f35-550c8326d7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggData(group_cols):\n",
    "    \n",
    "    df_results = df_push_commits_s.groupby(group_cols, sort=False, observed=True).agg(\n",
    "        unique_push_actors=('actor_id', 'nunique'),\n",
    "        unique_push_orgs=('org_id', 'nunique'),\n",
    "        push_size=('push_size_wt', 'sum'),\n",
    "        counted_commits=('push_head', 'count'),\n",
    "        retrieved_commits=('commit sha', 'count'),\n",
    "        unique_commit_authors=('commit author name', 'nunique'), \n",
    "        unique_commit_author_emails=('commit author email', 'nunique'),\n",
    "        unique_committers=('committer name', 'nunique'),\n",
    "        unique_committer_emails=('commmitter email', 'nunique'),\n",
    "        commit_authors=('commit author name', dropNAUnique),\n",
    "        committers=('committer info', dropNAUnique),\n",
    "        LOC_added=('commit additions', 'sum'),\n",
    "        avg_LOC_added=('commit additions', 'mean'),\n",
    "        LOC_deleted=('commit deletions', 'sum'),\n",
    "        avg_LOC_deleted=('commit deletions', 'mean'),\n",
    "        files_changed=('commit files changed count', 'sum'),\n",
    "        avg_files_changed=('commit files changed count', 'mean'),\n",
    "        changed_files=('commit file changes', getList),\n",
    "        uniq_changed_files=('commit file changes',  lambda x: len(getList(x)))\n",
    "    )    \n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12027420",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_push_commits_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fb132c-2291-47be-a9a8-a1d738da91a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "df_push_commits_s.to_csv(f'data/merged_data/{folder}/merged_commit_push.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a622c25d-c397-4a76-af4a-20b0ad136902",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"%%time\n",
    "df_push_commits_grouped_monthly = aggData(['repo_id', 'push_year', 'push_month'])\n",
    "df_push_commits_grouped_monthly.to_csv('data/aggregated_data/aggregated_monthly_labor.csv', encoding='utf-8')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cc8018-6e66-4d31-961f-77665bdb345a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"%%time\n",
    "df_push_commit_time_grouped_monthly = aggData(['repo_id', 'commit_year', 'commit_month'])\n",
    "df_push_commit_time_grouped_monthly.to_csv('data/aggregated_data/aggregated_monthly_labor_commit_time.csv', encoding='utf-8')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36bbc42-8703-4484-9da6-440fc601e42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"%%time\n",
    "df_push_commits_grouped_daily = aggData(['repo_id', 'push_year', 'push_month', 'push_day'])\n",
    "df_push_commits_grouped_daily.to_csv('data/aggregated_data/aggregated_daily_labor.csv', encoding='utf-8')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c3c751-fa03-4c72-aab1-522bed0f6e4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"%%time\n",
    "df_push_commit_time_grouped_daily = aggData(['repo_id', 'commit_year', 'commit_month', 'commit_day'])\n",
    "df_push_commit_time_grouped_daily.to_csv('data/aggregated_data/aggregated_daily_labor_commit_time.csv', encoding='utf-8')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f414f3b-690e-4ca1-a635-aa2e29249c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_actor_info.to_csv(f'data/merged_data/{folder}/push_actor.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02dcc1fa-13c5-4dcb-9bc1-3cd89f262dac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
