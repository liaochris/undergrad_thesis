{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cb3933e-cd68-4036-91f1-69ba41adfdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from pandarallel import pandarallel\n",
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "import requests\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "580fd57e-6b3d-445c-9417-6f8013ef9e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2bba744-a67c-4f0e-839f-ff504c1a07dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 32 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "pandarallel.initialize(progress_bar = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3e10ad-5201-4813-bb02-011b8e03e0c8",
   "metadata": {},
   "source": [
    "## OLD WORK PROBABLY NOT USEFUL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e452ea4-33c1-4788-a90e-1960f1bd903f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getints(field):\n",
    "    integers = []\n",
    "    for char in field:\n",
    "        try:        \n",
    "            value = int(char)\n",
    "            integers.append(str(value))\n",
    "        except ValueError:\n",
    "            break\n",
    "    return \"\".join(integers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19382be1-8846-4eae-b57c-08a4f7cd7f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanData(df, type, body_col, extract_cols):\n",
    "    df['issue_referenced_body'] = df.fillna('').apply(lambda x: '#' in x[body_col], axis = 1)\n",
    "    df['potential_issue_body'] = df.apply(\n",
    "        lambda x: [] if not x['issue_referenced_body'] else [getints(ele) for ele in x[body_col].split(\"#\")[1:] if getints(ele) != ''], axis = 1)\n",
    "\n",
    "    if type == 'pr': \n",
    "        df['issue_referenced_title'] = df.fillna('').apply(lambda x: '#' in x['pr_title'], axis = 1)\n",
    "        df['potential_issue_title'] = df.apply(\n",
    "            lambda x: [] if not x['issue_referenced_title'] \n",
    "            else [getints(ele) for ele in x['pr_title'].split(\"#\")[1:] if getints(ele) != '' ], axis = 1)\n",
    "        df['potential_issues'] = df.apply(lambda x: x['potential_issue_title'] + x['potential_issue_body'], axis = 1)\n",
    "    df['potential_issues'] = df.apply(lambda x: x['potential_issue_body'], axis = 1)\n",
    "    \n",
    "    return df[extract_cols]  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4f7d86-3b03-4c5a-9ab6-6170e6c70456",
   "metadata": {},
   "source": [
    "## PR Event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71b292b4-f156-452f-8091-db7218fab531",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_lst = glob.glob('data/github_clean/filtered_github_data/prEvent0*.csv')\n",
    "df_lst.extend(glob.glob('data/github_clean/github_data_pre_18/prEvent0*.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6dd410a-372f-463b-8017-365b1d68c5f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 9s, sys: 16.5 s, total: 1min 25s\n",
      "Wall time: 1min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pr_data = pd.concat([pd.read_csv(file, usecols = \n",
    "                                ['repo_id', 'repo_name', 'pr_id', 'pr_number', 'created_at','type','pr_issue_url', 'pr_title','pr_body']) for file in df_lst])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d52e7ed-a0e9-4758-8471-79edc052b642",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "linked_prs = cleanData(pr_data, 'pr', 'pr_body',\n",
    "                       ['repo_id', 'repo_name', 'pr_id', 'pr_number', 'potential_issues', 'created_at','type','pr_issue_url'])\n",
    "linked_prs = linked_prs[linked_prs['potential_issues'].apply(lambda x: len(x) != 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93870b43-56e2-4cba-b480-c1daa4605029",
   "metadata": {},
   "source": [
    "## PR Review Event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27957027-4816-4828-ae95-83f5c990ebbb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_lst_review = glob.glob('data/github_clean/filtered_github_data/prReviewEvent*.csv')\n",
    "df_lst_review.extend(glob.glob('data/github_clean/github_data_pre_18/prReviewEvent*.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4b2ac72-ace7-4404-a8a6-ff3d975d8576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36.2 s, sys: 3.17 s, total: 39.4 s\n",
      "Wall time: 58.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pr_review_data = pd.concat([pd.read_csv(file, usecols =\n",
    "                                       ['repo_id', 'repo_name', 'pr_review_id', 'pr_number', 'created_at','type', 'pr_review_body']) for file in df_lst_review])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21e83e5b-5d47-4edf-afaf-4d32882c511f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.9 s, sys: 585 ms, total: 13.4 s\n",
      "Wall time: 13.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_issues_linked_review = cleanData(pr_review_data, 'pr_review', 'pr_review_body',\n",
    "                                    ['repo_id', 'repo_name', 'pr_review_id', 'pr_number', 'potential_issues', 'created_at','type'])\n",
    "df_issues_linked_review = df_issues_linked_review[df_issues_linked_review['potential_issues'].apply(lambda x: len(x)>0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff469610-1a0b-4820-9a7f-872d2139ff10",
   "metadata": {},
   "source": [
    "# PR Review Comment Event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0456b325-b96e-4a61-af6f-79d18ce881ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lst_review_comment = glob.glob('data/github_clean/filtered_github_data/prReviewCommentEvent*.csv')\n",
    "df_lst_review_comment.extend(glob.glob('data/github_clean/github_data_pre_18/prReviewCommentEvent*.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29b251f2-973e-418f-a478-4e0c083e3f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 41.6 s, sys: 3.82 s, total: 45.4 s\n",
      "Wall time: 56.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pr_review_comment_data = pd.concat([pd.read_csv(file,\n",
    "                                               usecols = ['repo_id', 'repo_name', 'pr_review_comment_id', 'pr_number', 'created_at','type', 'pr_review_comment_body']) for file in df_lst_review_comment])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b631f55f-a9af-48ab-bd9d-5dbf8942465c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.7 s, sys: 4.75 s, total: 27.5 s\n",
      "Wall time: 27.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_issues_linked_review_comment = cleanData(pr_review_comment_data, 'pr_review_comment', 'pr_review_comment_body',\n",
    "                                            ['repo_id', 'repo_name', 'pr_review_comment_id', 'pr_number', 'potential_issues', 'created_at','type'])\n",
    "df_issues_linked_review_comment = df_issues_linked_review_comment[df_issues_linked_review_comment['potential_issues'].apply(lambda x: len(x) != 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7795c8f6-bdd8-4bfa-8d93-73d46d2f63e6",
   "metadata": {},
   "source": [
    "## Ensure we only have valid issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f43f365-c0cd-4e32-996b-f3d8a05665a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(fpath, colnames):\n",
    "    try:\n",
    "        return pd.read_csv(fpath, usecols = colnames)\n",
    "    except:\n",
    "        return pd.DataFrame(columns = colnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8cde78e7-3a54-4462-bcd2-70798c32a5d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 59s, sys: 11 s, total: 2min 10s\n",
      "Wall time: 2min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Read data on issue comments, issues\n",
    "issue_com = glob.glob('data/github_clean/filtered_github_data/issueCo*')\n",
    "issue_com.extend(glob.glob('data/github_clean/github_data_pre_18/issueCo*'))\n",
    "df_issue_comments = pd.concat([read_csv(ele, ['repo_id', 'repo_name', 'issue_number', 'created_at']) for ele in issue_com]).reset_index(drop = True)\n",
    "\n",
    "issues = glob.glob('data/github_clean/filtered_github_data/issues*')\n",
    "issues.extend(glob.glob('data/github_clean/github_data_pre_18/issues*'))\n",
    "df_issue = pd.concat([read_csv(ele, ['repo_id', 'repo_name', 'issue_number', 'created_at']) for ele in issues]).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cc627941-11fd-4e0e-8d32-62d442250056",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_issue_info = pd.concat([df_issue, df_issue_comments]).groupby(\n",
    "    ['repo_id','repo_name','issue_number'])['created_at'].min().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8dac2cf1-1c03-440e-a259-8cfb18397c56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pr data\n",
    "linked_pr_data = linked_prs[['repo_id', 'repo_name', 'pr_number', 'potential_issues','created_at']].explode('potential_issues')\n",
    "linked_pr_data['potential_issues'] = linked_pr_data['potential_issues'].astype(int)\n",
    "# pr review\n",
    "linked_pr_review_data = df_issues_linked_review_comment[['repo_id','repo_name', 'pr_number', 'potential_issues', 'created_at']].explode('potential_issues')\n",
    "linked_pr_review_data['potential_issues'] = pd.to_numeric(linked_pr_review_data['potential_issues'], errors = 'coerce')\n",
    "linked_pr_review_data = linked_pr_review_data[~linked_pr_review_data['potential_issues'].isna()]\n",
    "# pr review comment\n",
    "linked_pr_review_comment_data = df_issues_linked_review_comment[['repo_id', 'repo_name','pr_number', 'potential_issues', 'created_at']].explode('potential_issues')\n",
    "linked_pr_review_comment_data['potential_issues'] = pd.to_numeric(linked_pr_review_comment_data['potential_issues'], errors = 'coerce')\n",
    "linked_pr_review_comment_data = linked_pr_review_comment_data[~linked_pr_review_comment_data['potential_issues'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0b3b0fb5-93bf-4880-871c-0246935df5d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pr_issue_data = pd.concat([linked_pr_review_comment_data,linked_pr_review_data,linked_pr_data]).sort_values('created_at').drop_duplicates(\n",
    "    ['repo_id','repo_name','pr_number','potential_issues'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "03f079fc-3ac7-4427-bafa-dcf5064826d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_issue_info['key'] = all_issue_info['repo_id'].apply(lambda x: str(int(x)))+\"_\"+all_issue_info['issue_number'].apply(lambda x: str(int(x)))\n",
    "all_issue_info_dict = all_issue_info[['key', 'created_at']].set_index('key').to_dict()['created_at']\n",
    "pr_issue_data['issue_first_date'] = pr_issue_data.apply(lambda x: all_issue_info_dict.get(str(int(x['repo_id']))+\"_\"+str(int(x['potential_issues']))), axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a20c1a88-4d83-4c95-b98b-13574828d1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_issue_data['created_at'] = pd.to_datetime(pr_issue_data['created_at'])\n",
    "pr_issue_data['issue_first_date'] = pd.to_datetime(pr_issue_data['issue_first_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6986997d-3548-44f8-b802-1fbbed05d500",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pr_issue_data = pr_issue_data[pr_issue_data.apply(lambda x: not pd.isnull(x['issue_first_date']) and x['created_at'] >= x['issue_first_date'], axis = 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7eb74795-77c5-4da2-b5ea-db3a090c2782",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo_id</th>\n",
       "      <th>repo_name</th>\n",
       "      <th>potential_issues</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>845</th>\n",
       "      <td>921367</td>\n",
       "      <td>cobrateam/splinter</td>\n",
       "      <td>110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1739</th>\n",
       "      <td>1062237</td>\n",
       "      <td>libgit2/pygit2</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>1060073</td>\n",
       "      <td>omab/django-social-auth</td>\n",
       "      <td>156.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>1357152</td>\n",
       "      <td>erikrose/nose-progressive</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1705</th>\n",
       "      <td>1446474</td>\n",
       "      <td>pypa/virtualenv</td>\n",
       "      <td>186.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>79510167</td>\n",
       "      <td>pypa/pipenv</td>\n",
       "      <td>5836.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>75791177</td>\n",
       "      <td>rsheftel/pandas_market_calendars</td>\n",
       "      <td>279.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>102692863</td>\n",
       "      <td>onnx/onnx</td>\n",
       "      <td>4879.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>71932349</td>\n",
       "      <td>ray-project/ray</td>\n",
       "      <td>38857.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>71932349</td>\n",
       "      <td>ray-project/ray</td>\n",
       "      <td>38858.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192548 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        repo_id                         repo_name  potential_issues\n",
       "845      921367                cobrateam/splinter             110.0\n",
       "1739    1062237                    libgit2/pygit2              50.0\n",
       "317     1060073           omab/django-social-auth             156.0\n",
       "165     1357152         erikrose/nose-progressive              23.0\n",
       "1705    1446474                   pypa/virtualenv             186.0\n",
       "...         ...                               ...               ...\n",
       "146    79510167                       pypa/pipenv            5836.0\n",
       "101    75791177  rsheftel/pandas_market_calendars             279.0\n",
       "128   102692863                         onnx/onnx            4879.0\n",
       "452    71932349                   ray-project/ray           38857.0\n",
       "452    71932349                   ray-project/ray           38858.0\n",
       "\n",
       "[192548 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_issue_data[['repo_id','repo_name', 'potential_issues']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f15b08b-9ffd-4218-84a2-7fc95c12a5ed",
   "metadata": {},
   "source": [
    "## Ensure we only have valid PRs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "10656740-5779-419a-b7fd-ccf32690cbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pr_info = pd.concat([pr_data[['repo_id','repo_name', 'pr_number', 'created_at']],\n",
    "           pr_review_data[['repo_id','repo_name', 'pr_number', 'created_at']],\n",
    "           pr_review_comment_data[['repo_id','repo_name', 'pr_number', 'created_at']]]).sort_values('created_at').drop_duplicates(\n",
    "    ['repo_id','pr_number'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd81329e-bb25-4a42-bdf9-63f871ddd9a0",
   "metadata": {},
   "source": [
    "## Issue Comment Event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f89f41f1-4446-4936-8f32-5582201d9104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 50s, sys: 11.6 s, total: 2min 2s\n",
      "Wall time: 2min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Read data on issue comments, issues\n",
    "issue_com = glob.glob('data/github_clean/filtered_github_data/issueCo*')\n",
    "issue_com.extend(glob.glob('data/github_clean/github_data_pre_18/issueCo*'))\n",
    "df_issue_comments = pd.concat([pd.read_csv(ele, index_col = 0) for ele in issue_com]).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2d0e5f1e-5077-408d-960a-d6d34b78b811",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 36s, sys: 8.15 s, total: 1min 44s\n",
      "Wall time: 1min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_issue_comments_linked = cleanData(df_issue_comments, 'issue_comment', 'issue_comment_body',\n",
    "                                            ['repo_id', 'repo_name', 'issue_id', 'issue_number', \n",
    "                                             'potential_issues', 'created_at','type' , 'issue_pull_request'])\n",
    "df_issue_comments_linked = df_issue_comments_linked[df_issue_comments_linked['potential_issues'].apply(\n",
    "    lambda x: len(x) != 0)]\n",
    "df_issue_comments_linked.rename({'potential_issues':'potential_prs'}, axis = 1, inplace = True)\n",
    "df_issue_comments_linked = df_issue_comments_linked[~df_issue_comments_linked['issue_number'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a6cdf3be-1279-4e49-8dee-ac916371e353",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pr_info = all_pr_info[all_pr_info['pr_number'].apply(lambda x: type(x) != str and type(x) != float)]\n",
    "all_pr_info['key'] = all_pr_info['repo_id'].apply(lambda x: str(int(x)))+\"_\"+all_pr_info['pr_number'].apply(lambda x: str(int(x)))\n",
    "pr_info_dict = all_pr_info.set_index('key')['created_at'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6c50ad24-4a8e-4186-8317-ce79c2cf3518",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "linked_issue_comments = df_issue_comments_linked[['repo_id','repo_name', 'issue_number', 'potential_prs', 'created_at']].explode('potential_prs')\n",
    "linked_issue_comments['potential_prs'] = linked_issue_comments['potential_prs'].apply(lambda x: int(x))\n",
    "linked_issue_comments = linked_issue_comments.drop_duplicates()\n",
    "linked_issue_comments['key'] = linked_issue_comments['repo_id'].apply(lambda x: str(int(x)))+\"_\"+linked_issue_comments['potential_prs'].apply(lambda x: str(int(x)))\n",
    "linked_issue_comments['pr_created_date'] = linked_issue_comments['key'].apply(lambda x: pr_info_dict.get(x, np.nan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c687ea52-7cf7-4cbe-b9f5-03532741371a",
   "metadata": {},
   "outputs": [],
   "source": [
    "linked_issue_comments['key'] = linked_issue_comments['repo_id'].apply(lambda x: str(int(x)))+\"_\"+linked_issue_comments['potential_prs'].apply(lambda x: str(int(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "16547c6d-7407-486a-b3f4-a83e09336791",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "linked_issue_comments = linked_issue_comments[(~linked_issue_comments['pr_created_date'].isna()) & \\\n",
    "    (linked_issue_comments['created_at']>=linked_issue_comments['pr_created_date'])]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5005f6-d446-4269-aaf4-6ca3e4fafc5d",
   "metadata": {},
   "source": [
    "## Make sure the \"issues\" that are references are not PRs lmfao "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3f03aa0f-13b6-4978-ad7c-130b0edb1af0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "check_issues = pd.concat([\n",
    "    pr_issue_data[['repo_id', 'repo_name','potential_issues']].drop_duplicates(),\n",
    "    linked_issue_comments[['repo_id','repo_name', 'issue_number']].drop_duplicates().rename(\n",
    "        {'issue_number':'potential_issues'}, axis = 1)]).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "113bdb17-9679-4695-9bc9-5bd6943135cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_issues['linked_pr'] = np.nan\n",
    "check_issues['potential_issues'] = check_issues['potential_issues'].astype(int)\n",
    "check_issues = check_issues.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e7643716-142d-443b-9620-e7e43eb42f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"data/inputs/linked_issues\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "45a58238-a2c4-4844-8b4e-c15c29dfe589",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inds = np.array_split(check_issues.index, 1000)\n",
    "i = 0\n",
    "for ind in inds:\n",
    "    i+=1\n",
    "    check_issues.loc[ind].to_csv(f'data/inputs/linked_issues/linked_issue_{i}.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
