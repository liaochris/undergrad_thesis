{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b4c6a660-ea50-492e-8dbf-ddf179e20c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d7f7e190-a957-4136-9fe2-9420cd72823b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('data/merged_data/prEventData.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fb88b91b-ae73-44a4-89c8-cb6c0eef512c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/github_commits/parquet/github_data_2324/commits_push_pytorch___pytorch.parquet\n"
     ]
    }
   ],
   "source": [
    "for file in glob.glob(\"**/*\", recursive=True):\n",
    "    file_stats = os.stat(file)\n",
    "    mb_size = file_stats.st_size / (1024 * 1024)\n",
    "    if mb_size>=95:\n",
    "        print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "53d7693d-0265-407a-bff7-dfc145980879",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/merged_data/prEventData.parquet Size in MegaBytes is 248 has been partitioned\n",
      "data/merged_data/issue_data.parquet Size in MegaBytes is 394 has been partitioned\n",
      "data/github_commits/parquet/filtered_github_data/commits_pr_ray-project___ray.parquet Size in MegaBytes is 313 has been partitioned\n",
      "data/github_commits/parquet/filtered_github_data/commits_push_dagster-io___dagster.parquet Size in MegaBytes is 135 has been partitioned\n",
      "data/github_commits/parquet/filtered_github_data/commits_push_Azure___azure-sdk-for-python.parquet Size in MegaBytes is 242 has been partitioned\n",
      "data/github_commits/parquet/filtered_github_data/commits_pr_Azure___azure-cli.parquet Size in MegaBytes is 137 has been partitioned\n",
      "data/github_commits/parquet/github_data_2324/commits_push_home-assistant___core.parquet Size in MegaBytes is 131 has been partitioned\n",
      "data/github_commits/parquet/github_data_2324/commits_push_grpc___grpc.parquet Size in MegaBytes is 161 has been partitioned\n",
      "failed data/github_commits/parquet/github_data_2324/commits_push_pytorch___pytorch.parquet\n",
      "data/github_commits/parquet/github_data_2324/commits_pr_scikit-learn___scikit-learn.parquet Size in MegaBytes is 112 has been partitioned\n",
      "data/github_commits/parquet/github_data_2324/commits_push_Opentrons___opentrons.parquet Size in MegaBytes is 144 has been partitioned\n",
      "data/github_commits/parquet/github_data_2324/commits_push_sunpy___sunpy.parquet Size in MegaBytes is 137 has been partitioned\n",
      "data/github_commits/parquet/github_data_2324/commits_push_panda3d___panda3d.parquet Size in MegaBytes is 148 has been partitioned\n",
      "data/github_commits/parquet/github_data_2324/commits_push_googleapis___google-cloud-python.parquet Size in MegaBytes is 119 has been partitioned\n",
      "data/github_commits/parquet/github_data_2324/commits_pr_grpc___grpc.parquet Size in MegaBytes is 266 has been partitioned\n"
     ]
    }
   ],
   "source": [
    "for file in glob.glob(\"**/*.parquet\", recursive=True):\n",
    "    file_stats = os.stat(file)\n",
    "    mb_size = file_stats.st_size / (1024 * 1024)\n",
    "    if mb_size>=95:\n",
    "        try:\n",
    "            df = pd.read_parquet(file)\n",
    "            df.reset_index(drop = True, inplace = True)\n",
    "            partitions_count = math.ceil(mb_size/95) + 3\n",
    "            df_partitions = np.array_split(df, partitions_count)\n",
    "            for i in range(partitions_count):\n",
    "                df_partitions[i].to_parquet(file.replace(\".parquet\",f\"_p{i+1}.parquet\"))\n",
    "            print(f'{file} Size in MegaBytes is {file_stats.st_size / (1024 * 1024):.0f} has been partitioned')\n",
    "            os.remove(file)\n",
    "        except:\n",
    "            print(f\"failed {file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f712eaa-a9a1-4b2e-9bf6-9fd6eaa9990a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
